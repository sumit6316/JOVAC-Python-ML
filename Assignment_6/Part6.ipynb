{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "701df36e",
   "metadata": {},
   "source": [
    "Task 9: AdaBoost or Gradient Boosting \n",
    "\n",
    "● Train an AdaBoostClassifier or GradientBoostingClassifier. \n",
    "\n",
    "● Use a suitable dataset. \n",
    "\n",
    "● Compare it with Random Forest and Decision Tree in terms of: \n",
    "\n",
    "○ Accuracy \n",
    "○ F1-score \n",
    "○ Training time (optional) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd27b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64291417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Titanic dataset\n",
    "titanic = sns.load_dataset('titanic')\n",
    "titanic = titanic.drop(columns=['deck', 'embark_town', 'alive', 'who', 'adult_male', 'class'])\n",
    "titanic = titanic.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f7d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\n",
    "titanic['embarked'] = titanic['embarked'].map({'S': 0, 'C': 1, 'Q': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "722b546a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X = titanic[['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "y = titanic['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ebb729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79dd72cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=4, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=4, random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    start_time = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    end_time = time()\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    duration = end_time - start_time\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": round(acc, 4),\n",
    "        \"F1-Score\": round(f1, 4),\n",
    "        \"Training Time (s)\": round(duration, 4)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23021706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model  Accuracy  F1-Score  Training Time (s)\n",
      "2           AdaBoost    0.8112    0.7805             0.1382\n",
      "1      Random Forest    0.7902    0.7222             0.1161\n",
      "3  Gradient Boosting    0.7622    0.7018             0.1002\n",
      "0      Decision Tree    0.7063    0.6182             0.0021\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(by=\"Accuracy\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f3a56d",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "Gradient Boosting often yields the highest accuracy and F1-score, but takes longer to train.\n",
    "\n",
    "AdaBoost improves over base Decision Trees by focusing on errors.\n",
    "\n",
    "Random Forest is faster and robust but may underperform on complex patterns compared to boosting.\n",
    "\n",
    "Decision Tree is the fastest but also the least accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cac0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
